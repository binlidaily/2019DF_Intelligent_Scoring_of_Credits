{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文[参考](https://mp.weixin.qq.com/s?__biz=MzI5ODQxMTk5MQ==&mid=2247485727&idx=2&sn=411ac0329bdae3b5475e49d9af11b67f&chksm=eca77ba7dbd0f2b1fe5bd209f153f3797fc24093cebdeed0f292fd6c090bb36d9ef40991caf2&mpshare=1&scene=23&srcid=0227CpGIrhXsICJifSej0A3v#rd)-杰少，值得借鉴的地方：\n",
    "* MAE+MSE 的整合处理模式\n",
    "* MAE 和 MSE 结果的线性融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据工具包\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from tqdm import tqdm,tqdm_notebook \n",
    "\n",
    "\n",
    "## 字符串处理工具包\n",
    "import string\n",
    "import re\n",
    "# import gensim\n",
    "from collections import Counter\n",
    "import pickle\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "# from keras.preprocessing import text, sequence \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "\n",
    "import os \n",
    "import gc\n",
    "import joblib\n",
    "from scipy import stats \n",
    "from scipy.sparse import vstack  \n",
    "import time\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "import seaborn as sns \n",
    "tqdm.pandas() \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_dataset.csv')\n",
    "test = pd.read_csv('./data/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单特征工程\n",
    "def _simple_features(df_):\n",
    "    df = df_.copy() \n",
    "    df['次数'] = df['当月网购类应用使用次数'] +  df['当月物流快递类应用使用次数'] +  df['当月金融理财类应用使用总次数'] + df['当月视频播放类应用使用次数'] + df['当月飞机类应用使用次数'] + df['当月火车类应用使用次数'] + df['当月旅游资讯类应用使用次数']  + 1\n",
    "\n",
    "    for col in ['当月金融理财类应用使用总次数','当月旅游资讯类应用使用次数']: # 这两个比较积极向上一点\n",
    "        df[col + '百分比'] = df[col].values / df['次数'].values \n",
    "\n",
    "    df['当月通话人均话费'] = df['用户账单当月总费用（元）'].values / (df['当月通话交往圈人数'].values + 1)\n",
    "    df['上个月费用'] = df['用户当月账户余额（元）'].values + df['用户账单当月总费用（元）'].values\n",
    "    df['用户上网年龄'] = df['用户年龄'] - df['用户网龄（月）']\n",
    "    df['用户上网年龄百分比'] = df['用户网龄（月）'] / (df['用户年龄'] + 1)\n",
    "    df['近似总消费'] = df['用户近6个月平均消费值（元）'] / 6 * df['用户网龄（月）']\n",
    "    return df\n",
    "\n",
    "# run\n",
    "train_fea = _simple_features(train)\n",
    "test_fea  = _simple_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_cols = [col for col in train_fea.columns if train_fea[col].dtypes!='object' and train_fea[col].dtypes != '<M8[ns]' and col!='用户编码' and col!='信用分']   \n",
    "len(fea_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线下验证函数\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def _get_values_lgbregresser_models(df_fea, df_label,  feature_names):\n",
    "    kf = KFold(n_splits=5,shuffle=False)#,random_state=1)\n",
    "\n",
    "    models  = [] \n",
    "    models_1 = []\n",
    "    models_2 = []\n",
    "\n",
    "    importances = pd.DataFrame() \n",
    "    lgb_params = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'mse',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "#          'n_estimators': 10000,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": 50,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "    lgb_params1 = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 32, \n",
    "         'objective':'mae',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "#          'n_estimators': 10000,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"nthread\": 50,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "    min_val = np.min(df_label)\n",
    "    print(min_val)\n",
    "    for fold_, (trn_, val_) in enumerate(kf.split(df_fea)): \n",
    "        trn_x, trn_y= df_fea[trn_,:], df_label[trn_]#, df_label1[trn_] \n",
    "        val_x, val_y = df_fea[val_,:], df_label[val_]#, df_label1[val_] \n",
    "        tmp = pd.DataFrame()\n",
    "\n",
    "        model = lgb.LGBMRegressor(**lgb_params1)\n",
    "        model.fit(trn_x, trn_y, eval_set=[(trn_x, trn_y), (val_x, val_y)], eval_metric ='mae',verbose=50,early_stopping_rounds=250)     \n",
    "        tmp['target'] = val_y\n",
    "        tmp['pred1'] = model.predict(val_x)\n",
    "        models.append(model)\n",
    "\n",
    "        model1 = lgb.LGBMRegressor(**lgb_params)\n",
    "        model1.fit(trn_x, trn_y, eval_set=[(trn_x, trn_y), (val_x, val_y)], eval_metric ='mae',verbose=50,early_stopping_rounds=250)     \n",
    "        tmp['pred2'] = model1.predict(val_x)\n",
    "        models_1.append(model1)\n",
    "\n",
    "        tmp = tmp.sort_values('pred1')\n",
    "        tmp['ranks'] = list(range(tmp.shape[0]))\n",
    "        tmp['preds'] = tmp['pred1'].values\n",
    "        tmp.loc[tmp.ranks<2000,'preds']  = tmp.loc[tmp.ranks< 2000,'pred2'].values *0.4 + tmp.loc[tmp.ranks< 2000,'pred1'].values * 0.6\n",
    "        tmp.loc[tmp.ranks>8000,'preds']  = tmp.loc[tmp.ranks> 8000,'pred2'].values *0.4 + tmp.loc[tmp.ranks> 8000,'pred1'].values * 0.6\n",
    "         \n",
    "        print('*' * 100)\n",
    "        print('MAE Model',     1 / (1 + (mean_absolute_error(y_true= tmp['target'] , y_pred= tmp['pred1'] ))))\n",
    "        print('MSE Model',     1 / (1 + (mean_absolute_error(y_true= tmp['target'] , y_pred= tmp['pred2'] ))))\n",
    "        print('Merge Model12', 1 / (1 + (mean_absolute_error(y_true= tmp['target'] , y_pred= tmp['preds'] )))) \n",
    "\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = feature_names\n",
    "        imp_df['gain'] = model.feature_importances_\n",
    "        imp_df['fold'] = fold_ + 1\n",
    "        importances = pd.concat([importances, imp_df], axis=0)\n",
    "        gc.collect() \n",
    "\n",
    "    return models,models_1,importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 27.6643\tvalid_1's l1: 27.89\n",
      "[100]\tvalid_0's l1: 23.9312\tvalid_1's l1: 24.1528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.9312\tvalid_1's l1: 24.1528\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 28.1296\tvalid_1's l1: 28.3201\n",
      "[100]\tvalid_0's l1: 24.1561\tvalid_1's l1: 24.3807\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.1561\tvalid_1's l1: 24.3807\n",
      "****************************************************************************************************\n",
      "('MAE Model', 0.03975702918993141)\n",
      "('MSE Model', 0.03940002012682151)\n",
      "('Merge Model12', 0.03998108581012781)\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 27.6766\tvalid_1's l1: 27.9675\n",
      "[100]\tvalid_0's l1: 23.9536\tvalid_1's l1: 24.2647\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.9536\tvalid_1's l1: 24.2647\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 28.1362\tvalid_1's l1: 28.311\n",
      "[100]\tvalid_0's l1: 24.1638\tvalid_1's l1: 24.3314\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.1638\tvalid_1's l1: 24.3314\n",
      "****************************************************************************************************\n",
      "('MAE Model', 0.039580873073719096)\n",
      "('MSE Model', 0.0394767650618662)\n",
      "('Merge Model12', 0.039870285687377015)\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 27.7196\tvalid_1's l1: 27.7228\n",
      "[100]\tvalid_0's l1: 23.99\tvalid_1's l1: 24.0139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.99\tvalid_1's l1: 24.0139\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 28.1825\tvalid_1's l1: 28.3248\n",
      "[100]\tvalid_0's l1: 24.218\tvalid_1's l1: 24.3704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.218\tvalid_1's l1: 24.3704\n",
      "****************************************************************************************************\n",
      "('MAE Model', 0.03997783457651246)\n",
      "('MSE Model', 0.03941600553343979)\n",
      "('Merge Model12', 0.04018226613229619)\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 27.8103\tvalid_1's l1: 27.3117\n",
      "[100]\tvalid_0's l1: 24.0602\tvalid_1's l1: 23.6933\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.0602\tvalid_1's l1: 23.6933\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 28.2863\tvalid_1's l1: 27.8208\n",
      "[100]\tvalid_0's l1: 24.286\tvalid_1's l1: 23.9475\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.286\tvalid_1's l1: 23.9475\n",
      "****************************************************************************************************\n",
      "('MAE Model', 0.04049673982139718)\n",
      "('MSE Model', 0.04008413229957657)\n",
      "('Merge Model12', 0.040729288639306395)\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 27.6762\tvalid_1's l1: 27.8842\n",
      "[100]\tvalid_0's l1: 23.9459\tvalid_1's l1: 24.1749\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.9459\tvalid_1's l1: 24.1749\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[50]\tvalid_0's l1: 28.1321\tvalid_1's l1: 28.2395\n",
      "[100]\tvalid_0's l1: 24.1599\tvalid_1's l1: 24.2584\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.1599\tvalid_1's l1: 24.2584\n",
      "****************************************************************************************************\n",
      "('MAE Model', 0.03972213637245678)\n",
      "('MSE Model', 0.03959076011890152)\n",
      "('Merge Model12', 0.039973930848955945)\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "models_mae, models_mse, importances = _get_values_lgbregresser_models(train_fea[fea_cols].values, train_fea['信用分'].values, feature_names=fea_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       623.632800\n",
       "std         13.473317\n",
       "min        596.000000\n",
       "25%        614.000000\n",
       "50%        627.000000\n",
       "75%        634.000000\n",
       "max        641.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE 提交\n",
    "pred_mae = 0\n",
    "for i,model in enumerate(models_mae): \n",
    "    pred_mae += model.predict(test_fea[fea_cols]) * 0.2\n",
    "test_fea['pred_mae'] = pred_mae\n",
    "\n",
    "# MSE 提交\n",
    "pred_mse = 0\n",
    "for i,model in enumerate(models_mse): \n",
    "    pred_mse += model.predict(test_fea[fea_cols]) * 0.2\n",
    "test_fea['pred_mse'] = pred_mse\n",
    "\n",
    "submit_mae = pd.DataFrame()\n",
    "submit_mae['id']    = test_fea['用户编码'].values\n",
    "submit_mae['score'] = test_fea['pred_mae'].values \n",
    "submit_mae['score'] = submit_mae['score'].astype(int)\n",
    "submit_mae[['id','score']].to_csv('baseline_mae.csv',index = None)\n",
    "submit_mae['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       622.623660\n",
       "std         13.979832\n",
       "min        588.000000\n",
       "25%        614.000000\n",
       "50%        627.000000\n",
       "75%        634.000000\n",
       "max        640.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE+MSE 提交 简单的线性融合\n",
    "test_fea = test_fea.sort_values('pred_mae')\n",
    "test_fea['ranks'] = list(range(test_fea.shape[0]))\n",
    "test_fea['score'] = test_fea['pred_mae'].values\n",
    "test_fea.loc[test_fea.ranks<10000,'score']  = test_fea.loc[test_fea.ranks< 10000,'pred_mse'].values *0.4 + test_fea.loc[test_fea.ranks< 10000,'pred_mae'].values * 0.6\n",
    "test_fea.loc[test_fea.ranks>40000,'score']  = test_fea.loc[test_fea.ranks> 40000,'pred_mse'].values *0.4 + test_fea.loc[test_fea.ranks> 40000,'pred_mae'].values * 0.6\n",
    "\n",
    "submit_mae_mse = pd.DataFrame()\n",
    "submit_mae_mse['id']    = test_fea['用户编码'].values\n",
    "submit_mae_mse['score'] = test_fea['score'].values \n",
    "submit_mae_mse['score'] = submit_mae_mse['score'].astype(int)\n",
    "submit_mae_mse[['id','score']].to_csv('baseline_mae_mse.csv',index = None)\n",
    "submit_mae_mse['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Conda",
   "language": "/Users/Bin/anaconda2/envs/py2/bin/python",
   "name": "python_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
