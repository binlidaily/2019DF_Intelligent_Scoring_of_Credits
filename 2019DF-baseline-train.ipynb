{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "# show more columns with trian_df.describe()\n",
    "pd.set_option('display.max_columns', 50)\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf-8')\n",
    "import time\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False # 用来正常显示负号\n",
    "# plt.plot([-1,2,-5,3])\n",
    "# plt.title(u'中文',fontproperties=myfont)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_dir = '../dataset/DataFountain2019-消费者人群画像/'\n",
    "train_df = pd.read_csv(data_dir + 'train_dataset.csv')\n",
    "test_df = pd.read_csv(data_dir + 'test_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_process(data_df):\n",
    "    transform_value_feats = ['用户年龄', '用户网龄（月）', '当月通话交往圈人数', '近三个月月均商场出现次数',\n",
    "                            '当月网购类应用使用次数', '当月物流快递类应用使用次数', '当月金融理财类应用使用总次数', \n",
    "                             '当月视频播放类应用使用次数', '当月飞机类应用使用次数', '当月火车类应用使用次数', \n",
    "                             '当月旅游资讯类应用使用次数']\n",
    "    bill_feats = ['缴费用户最近一次缴费金额（元）', '用户近6个月平均消费值（元）','用户账单当月总费用（元）', \n",
    "                   '用户当月账户余额（元）']\n",
    "    log_feats = ['当月网购类应用使用次数', '当月金融理财类应用使用总次数', '当月视频播放类应用使用次数']\n",
    "    \n",
    "    # 处理极小或极大的离散点\n",
    "    for col in transform_value_feats + bill_feats:\n",
    "        up_limit = np.percentile(data_df[col].values, 99.9) # 99.9%分位数\n",
    "        low_limit = np.percentile(data_df[col].values, 0.1) # 0.1%分位数\n",
    "        data_df.loc[data_df[col] > up_limit, col] = up_limit\n",
    "        data_df.loc[data_df[col] < low_limit, col] = low_limit\n",
    "    \n",
    "    # 解决正太分布左偏的情况，取对数\n",
    "    for col in bill_feats + log_feats:\n",
    "        data_df[col] = data_df[col].map(lambda x : np.log1p(x))\n",
    "    \n",
    "    # 异常值处理\n",
    "    ## 对年龄异常值取\n",
    "    data_df.loc[data_df['用户年龄'] == 0, '用户年龄'] = data_df['用户年龄'].mode().values # 线下测试，众数比平均数好\n",
    "    ## 用户话费敏感度处理\n",
    "    data_df.loc[data_df['用户话费敏感度'] == 0, '用户话费敏感度'] = data_df['用户话费敏感度'].mode().values\n",
    "    \n",
    "\n",
    "    # 用户费用相关特征\n",
    "    ## 不同的充值路径\n",
    "    data_df['不同充值途径'] = 0\n",
    "    data_df.loc[(data_df['缴费用户最近一次缴费金额（元）'] % 10 == 0) & \n",
    "                      (data_df['缴费用户最近一次缴费金额（元）'] != 0), '不同充值途径'] = 1\n",
    "    ## 费用稳定性\n",
    "    data_df['当前费用稳定性'] = data_df['用户账单当月总费用（元）'] / (data_df['用户近6个月平均消费值（元）'] + 1)\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "# run\n",
    "train_df = base_process(train_df)\n",
    "test_df = base_process(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my methods to create new features\n",
    "def create_features(data_df):\n",
    "    # 异常值处理\n",
    "    ## 对年龄异常值取\n",
    "    data_df.loc[data_df['用户年龄'] == 0, '用户年龄'] = data_df['用户年龄'].mode() # 线下测试，众数比平均数好\n",
    "    ## 用户话费敏感度处理\n",
    "    data_df.loc[data_df['用户话费敏感度'] == 0, '用户话费敏感度'] = data_df['用户话费敏感度'].mode()\n",
    "    \n",
    "\n",
    "    # 用户费用相关特征\n",
    "    ## 不同的充值路径\n",
    "    data_df['不同充值途径'] = 0\n",
    "    data_df.loc[(data_df['缴费用户最近一次缴费金额（元）'] % 10 == 0) & \n",
    "                      (data_df['缴费用户最近一次缴费金额（元）'] != 0), '不同充值途径'] = 1\n",
    "    ## 费用稳定性\n",
    "    data_df['当前费用稳定性'] = data_df['用户账单当月总费用（元）'] / (data_df['用户近6个月平均消费值（元）'] + 1)\n",
    "   \n",
    "    # 构造 ratio 比例特征\n",
    "    ## '缴费用户最近一次缴费金额（元）'/'用户当月账户余额（元）'\n",
    "    data_df['充值_余额_比例'] = data_df['缴费用户最近一次缴费金额（元）'] / (data_df['用户当月账户余额（元）'] + 1)\n",
    "    ## 用户账单当月总费用/当月账户余额\n",
    "    data_df['月费_余额_比例'] = data_df['用户账单当月总费用（元）'] / (data_df['用户当月账户余额（元）'] + 1)\n",
    "    # '用户账单当月总费用（元）'/ '缴费用户最近一次缴费金额（元）'\n",
    "    data_df['月费_缴费_比例'] = data_df['用户账单当月总费用（元）'] / (data_df['缴费用户最近一次缴费金额（元）'] + 1)\n",
    "    ## '用户近6个月平均消费值（元）'/ '缴费用户最近一次缴费金额（元）'\n",
    "    data_df['均费_缴费_比例'] = data_df['用户近6个月平均消费值（元）'] / (data_df['缴费用户最近一次缴费金额（元）'] + 1)\n",
    "    ## '用户近6个月平均消费值（元）' / \n",
    "    data_df['均费_月费_比例'] = data_df['用户近6个月平均消费值（元）'] / (data_df['用户账单当月总费用（元）'] + 1)\n",
    "    \n",
    "    ## 用户上网年龄\n",
    "    data_df['用户上网年龄'] = data_df['用户年龄'] - data_df['用户网龄（月）']\n",
    "#     ## '用户网龄（月）'/'用户年龄', '用户年龄'/ '用户网龄（月）'不是很好算出来，毕竟是个大数\n",
    "#     data_df['网龄_年龄_比例'] = data_df['用户网龄（月）'] / (data_df['用户年龄'] + 1)\n",
    "    \n",
    "    \n",
    "    # 构造加减特征\n",
    "    data_df['缴费金额是否能覆盖当月账单'] = data_df['缴费用户最近一次缴费金额（元）'] - data_df['用户账单当月总费用（元）']\n",
    "    data_df['最近一次缴费是否超过平均消费额'] = data_df['缴费用户最近一次缴费金额（元）'] - data_df['用户近6个月平均消费值（元）']\n",
    "    data_df['当月账单是否超过平均消费额'] = data_df['用户账单当月总费用（元）'] - data_df['用户近6个月平均消费值（元）']\n",
    "    \n",
    "    # 对 bool 特征进行简单构造\n",
    "    data_df['是否去过高档商场'] = data_df['当月是否到过福州山姆会员店'] + data_df['当月是否逛过福州仓山万达']\n",
    "    ## 检查后发现结果为2的比较稀少，于是将1、2都归到1中\n",
    "    data_df['是否去过高档商场'] = data_df['是否去过高档商场'].map(lambda x : 1 if x >= 1 else 0)\n",
    "    \n",
    "    \n",
    "    data_df['是否_商场_电影'] = data_df['是否去过高档商场'] * data_df['当月是否看电影']\n",
    "    data_df['是否_商场_旅游'] = data_df['是否去过高档商场'] * data_df['当月是否景点游览']\n",
    "    data_df['是否_商场_体育馆'] = data_df['是否去过高档商场'] * data_df['当月是否体育场馆消费']\n",
    "    data_df['是否_电影_体育馆'] = data_df['当月是否看电影'] * data_df['当月是否体育场馆消费']\n",
    "    data_df['是否_电影_旅游'] = data_df['当月是否看电影'] * data_df['当月是否景点游览']\n",
    "    data_df['是否_旅游_体育馆'] = data_df['当月是否景点游览'] * data_df['当月是否体育场馆消费']\n",
    "    \n",
    "    data_df['是否_商场_旅游_体育馆'] = data_df['是否去过高档商场'] * data_df['当月是否景点游览'] * data_df['当月是否体育场馆消费']\n",
    "    data_df['是否_商场_电影_体育馆'] = data_df['是否去过高档商场'] * data_df['当月是否看电影'] * data_df['当月是否体育场馆消费']\n",
    "    data_df['是否_商场_电影_旅游'] = data_df['是否去过高档商场'] * data_df['当月是否看电影'] * data_df['当月是否景点游览']\n",
    "    data_df['是否_体育馆_电影_旅游'] = data_df['当月是否体育场馆消费'] * data_df['当月是否看电影'] * data_df['当月是否景点游览']\n",
    "    \n",
    "    data_df['是否_商场_体育馆_电影_旅游'] = data_df['是否去过高档商场'] * data_df['当月是否体育场馆消费'] * \\\n",
    "                                        data_df['当月是否看电影'] * data_df['当月是否景点游览']\n",
    "    \n",
    "#     # 杰少特征参考\n",
    "#     data_df['次数'] = data_df['当月网购类应用使用次数'] +  data_df['当月物流快递类应用使用次数'] +  data_df['当月金融理财类应用使用总次数'] + \\\n",
    "#                 data_df['当月视频播放类应用使用次数'] + data_df['当月飞机类应用使用次数'] + data_df['当月火车类应用使用次数'] + \\\n",
    "#                 data_df['当月旅游资讯类应用使用次数']  + 1\n",
    "\n",
    "#     for col in ['当月金融理财类应用使用总次数', '当月旅游资讯类应用使用次数']: # 这两个比较积极向上一点\n",
    "#         data_df[col + '百分比'] = data_df[col] / data_df['次数'] \n",
    "\n",
    "#     data_df['当月通话人均话费'] = data_df['用户账单当月总费用（元）'] / (data_df['当月通话交往圈人数'] + 1)\n",
    "\n",
    "#     data_df['上个月费用'] = data_df['用户当月账户余额（元）'] + data_df['用户账单当月总费用（元）']\n",
    "\n",
    "#     data_df['近似总消费'] = data_df['用户近6个月平均消费值（元）'] * data_df['用户网龄（月）'] / 12\n",
    "    \n",
    "    \n",
    "    return data_df\n",
    "\n",
    "# run\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scale = ['用户年龄', '用户网龄（月）', '用户最近一次缴费距今时长（月）', '缴费用户最近一次缴费金额（元）', \\\n",
    "             '用户近6个月平均消费值（元）', '用户账单当月总费用（元）', '用户当月账户余额（元）', '当月通话交往圈人数',\\\n",
    "            '近三个月月均商场出现次数', '当月网购类应用使用次数', '当月物流快递类应用使用次数', '当月金融理财类应用使用总次数',\\\n",
    "            '当月视频播放类应用使用次数', '当月飞机类应用使用次数', '当月火车类应用使用次数', '当月旅游资讯类应用使用次数', \\\n",
    "             '当前费用稳定性']\n",
    "\n",
    "def standrad_scale_columns(data_df, std_cols):\n",
    "    ss = StandardScaler()\n",
    "    std_scaled = pd.DataFrame(ss.fit_transform(data_df[std_cols]), columns=std_cols)\n",
    "    data_df.drop(std_cols, axis=1)\n",
    "    data_df.merge(std_scaled)\n",
    "    return data_df\n",
    "\n",
    "# Run\n",
    "train_df = standrad_scale_columns(train_df, std_scale)\n",
    "test_df = standrad_scale_columns(test_df, std_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户实名制是否通过核实</th>\n",
       "      <th>用户年龄</th>\n",
       "      <th>是否大学生客户</th>\n",
       "      <th>是否黑名单客户</th>\n",
       "      <th>是否4G不健康客户</th>\n",
       "      <th>用户网龄（月）</th>\n",
       "      <th>用户最近一次缴费距今时长（月）</th>\n",
       "      <th>缴费用户最近一次缴费金额（元）</th>\n",
       "      <th>用户近6个月平均消费值（元）</th>\n",
       "      <th>用户账单当月总费用（元）</th>\n",
       "      <th>用户当月账户余额（元）</th>\n",
       "      <th>缴费用户当前是否欠费缴费</th>\n",
       "      <th>用户话费敏感度</th>\n",
       "      <th>当月通话交往圈人数</th>\n",
       "      <th>是否经常逛商场的人</th>\n",
       "      <th>近三个月月均商场出现次数</th>\n",
       "      <th>当月是否逛过福州仓山万达</th>\n",
       "      <th>当月是否到过福州山姆会员店</th>\n",
       "      <th>当月是否看电影</th>\n",
       "      <th>当月是否景点游览</th>\n",
       "      <th>当月是否体育场馆消费</th>\n",
       "      <th>当月网购类应用使用次数</th>\n",
       "      <th>当月物流快递类应用使用次数</th>\n",
       "      <th>当月金融理财类应用使用总次数</th>\n",
       "      <th>当月视频播放类应用使用次数</th>\n",
       "      <th>...</th>\n",
       "      <th>当月旅游资讯类应用使用次数</th>\n",
       "      <th>信用分</th>\n",
       "      <th>不同充值途径</th>\n",
       "      <th>当前费用稳定性</th>\n",
       "      <th>充值_余额_比例</th>\n",
       "      <th>月费_余额_比例</th>\n",
       "      <th>月费_缴费_比例</th>\n",
       "      <th>均费_缴费_比例</th>\n",
       "      <th>均费_月费_比例</th>\n",
       "      <th>用户上网年龄</th>\n",
       "      <th>缴费金额是否能覆盖当月账单</th>\n",
       "      <th>最近一次缴费是否超过平均消费额</th>\n",
       "      <th>当月账单是否超过平均消费额</th>\n",
       "      <th>是否去过高档商场</th>\n",
       "      <th>是否_商场_电影</th>\n",
       "      <th>是否_商场_旅游</th>\n",
       "      <th>是否_商场_体育馆</th>\n",
       "      <th>是否_电影_体育馆</th>\n",
       "      <th>是否_电影_旅游</th>\n",
       "      <th>是否_旅游_体育馆</th>\n",
       "      <th>是否_商场_旅游_体育馆</th>\n",
       "      <th>是否_商场_电影_体育馆</th>\n",
       "      <th>是否_商场_电影_旅游</th>\n",
       "      <th>是否_体育馆_电影_旅游</th>\n",
       "      <th>是否_商场_体育馆_电影_旅游</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.99022</td>\n",
       "      <td>38.039200</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.088580</td>\n",
       "      <td>96.445220</td>\n",
       "      <td>0.700100</td>\n",
       "      <td>2.871785</td>\n",
       "      <td>4.404703</td>\n",
       "      <td>4.388804</td>\n",
       "      <td>4.272673</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>3.353120</td>\n",
       "      <td>47.862083</td>\n",
       "      <td>0.329500</td>\n",
       "      <td>26.572520</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.242280</td>\n",
       "      <td>0.47442</td>\n",
       "      <td>0.37412</td>\n",
       "      <td>4.798474</td>\n",
       "      <td>0.700361</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>5.159212</td>\n",
       "      <td>...</td>\n",
       "      <td>17.133007</td>\n",
       "      <td>618.053060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808802</td>\n",
       "      <td>0.555747</td>\n",
       "      <td>0.851325</td>\n",
       "      <td>1.843264</td>\n",
       "      <td>1.858965</td>\n",
       "      <td>0.816685</td>\n",
       "      <td>-58.406020</td>\n",
       "      <td>-1.517019</td>\n",
       "      <td>-1.532918</td>\n",
       "      <td>-0.015899</td>\n",
       "      <td>0.056960</td>\n",
       "      <td>0.029640</td>\n",
       "      <td>0.050940</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.259060</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.110840</td>\n",
       "      <td>0.023940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.09841</td>\n",
       "      <td>11.205465</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.215452</td>\n",
       "      <td>0.284139</td>\n",
       "      <td>59.159031</td>\n",
       "      <td>0.458218</td>\n",
       "      <td>1.968189</td>\n",
       "      <td>0.670481</td>\n",
       "      <td>0.719068</td>\n",
       "      <td>0.927934</td>\n",
       "      <td>0.223116</td>\n",
       "      <td>1.239894</td>\n",
       "      <td>51.517806</td>\n",
       "      <td>0.470036</td>\n",
       "      <td>32.789251</td>\n",
       "      <td>0.192881</td>\n",
       "      <td>0.162435</td>\n",
       "      <td>0.428467</td>\n",
       "      <td>0.49935</td>\n",
       "      <td>0.48390</td>\n",
       "      <td>2.761002</td>\n",
       "      <td>9.243785</td>\n",
       "      <td>2.917810</td>\n",
       "      <td>3.260769</td>\n",
       "      <td>...</td>\n",
       "      <td>93.983089</td>\n",
       "      <td>42.443022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059803</td>\n",
       "      <td>0.386572</td>\n",
       "      <td>0.176877</td>\n",
       "      <td>1.513286</td>\n",
       "      <td>1.526498</td>\n",
       "      <td>0.055808</td>\n",
       "      <td>56.534559</td>\n",
       "      <td>1.830333</td>\n",
       "      <td>1.837686</td>\n",
       "      <td>0.269912</td>\n",
       "      <td>0.231768</td>\n",
       "      <td>0.169594</td>\n",
       "      <td>0.219877</td>\n",
       "      <td>0.205984</td>\n",
       "      <td>0.35351</td>\n",
       "      <td>0.373247</td>\n",
       "      <td>0.438123</td>\n",
       "      <td>0.200545</td>\n",
       "      <td>0.155456</td>\n",
       "      <td>0.164458</td>\n",
       "      <td>0.313937</td>\n",
       "      <td>0.152864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.131392</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127589</td>\n",
       "      <td>0.168736</td>\n",
       "      <td>0.348693</td>\n",
       "      <td>0.511288</td>\n",
       "      <td>-244.000000</td>\n",
       "      <td>-6.353069</td>\n",
       "      <td>-6.104704</td>\n",
       "      <td>-4.067160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.010601</td>\n",
       "      <td>3.982947</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.746553</td>\n",
       "      <td>0.837569</td>\n",
       "      <td>0.841298</td>\n",
       "      <td>0.790764</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-3.101892</td>\n",
       "      <td>-3.285038</td>\n",
       "      <td>-0.092383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.929863</td>\n",
       "      <td>4.503359</td>\n",
       "      <td>4.506675</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.525453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.590987</td>\n",
       "      <td>5.817111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818677</td>\n",
       "      <td>0.713113</td>\n",
       "      <td>0.836579</td>\n",
       "      <td>0.951618</td>\n",
       "      <td>0.947006</td>\n",
       "      <td>0.819245</td>\n",
       "      <td>-57.000000</td>\n",
       "      <td>-0.760483</td>\n",
       "      <td>-0.737390</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.613138</td>\n",
       "      <td>4.884013</td>\n",
       "      <td>4.904867</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.838405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.045994</td>\n",
       "      <td>7.793277</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839307</td>\n",
       "      <td>0.834068</td>\n",
       "      <td>0.936021</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.250762</td>\n",
       "      <td>0.839817</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-0.123937</td>\n",
       "      <td>-0.137328</td>\n",
       "      <td>0.083247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>6.104704</td>\n",
       "      <td>6.353069</td>\n",
       "      <td>7.867500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>536.003000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>10.817839</td>\n",
       "      <td>203.001000</td>\n",
       "      <td>9.993604</td>\n",
       "      <td>11.611085</td>\n",
       "      <td>...</td>\n",
       "      <td>1814.027000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.171898</td>\n",
       "      <td>1.828958</td>\n",
       "      <td>1.869707</td>\n",
       "      <td>6.353069</td>\n",
       "      <td>6.104704</td>\n",
       "      <td>2.439040</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.573722</td>\n",
       "      <td>3.303590</td>\n",
       "      <td>1.763218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       用户实名制是否通过核实          用户年龄       是否大学生客户       是否黑名单客户     是否4G不健康客户  \\\n",
       "count  50000.00000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.99022     38.039200      0.003720      0.048800      0.088580   \n",
       "std        0.09841     11.205465      0.060879      0.215452      0.284139   \n",
       "min        0.00000      9.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.00000     30.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.00000     36.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.00000     45.000000      0.000000      0.000000      0.000000   \n",
       "max        1.00000     84.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            用户网龄（月）  用户最近一次缴费距今时长（月）  缴费用户最近一次缴费金额（元）  用户近6个月平均消费值（元）  \\\n",
       "count  50000.000000     50000.000000     50000.000000    50000.000000   \n",
       "mean      96.445220         0.700100         2.871785        4.404703   \n",
       "std       59.159031         0.458218         1.968189        0.670481   \n",
       "min        5.000000         0.000000         0.000000        2.197225   \n",
       "25%       48.000000         0.000000         0.000000        4.010601   \n",
       "50%       94.000000         1.000000         3.929863        4.503359   \n",
       "75%      139.000000         1.000000         4.613138        4.884013   \n",
       "max      273.000000         1.000000         6.214608        6.104704   \n",
       "\n",
       "       用户账单当月总费用（元）   用户当月账户余额（元）  缴费用户当前是否欠费缴费       用户话费敏感度     当月通话交往圈人数  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       4.388804      4.272673      0.052540      3.353120     47.862083   \n",
       "std        0.719068      0.927934      0.223116      1.239894     51.517806   \n",
       "min        1.131392      2.397895      0.000000      1.000000      1.000000   \n",
       "25%        3.982947      3.713572      0.000000      2.000000     16.000000   \n",
       "50%        4.506675      4.262680      0.000000      4.000000     32.000000   \n",
       "75%        4.904867      4.875197      0.000000      4.000000     61.000000   \n",
       "max        6.353069      7.867500      1.000000      5.000000    536.003000   \n",
       "\n",
       "          是否经常逛商场的人  近三个月月均商场出现次数  当月是否逛过福州仓山万达  当月是否到过福州山姆会员店       当月是否看电影  \\\n",
       "count  50000.000000  50000.000000  50000.000000   50000.000000  50000.000000   \n",
       "mean       0.329500     26.572520      0.038700       0.027120      0.242280   \n",
       "std        0.470036     32.789251      0.192881       0.162435      0.428467   \n",
       "min        0.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "25%        0.000000      1.000000      0.000000       0.000000      0.000000   \n",
       "50%        0.000000      8.000000      0.000000       0.000000      0.000000   \n",
       "75%        1.000000     50.000000      0.000000       0.000000      0.000000   \n",
       "max        1.000000     92.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "          当月是否景点游览   当月是否体育场馆消费   当月网购类应用使用次数  当月物流快递类应用使用次数  当月金融理财类应用使用总次数  \\\n",
       "count  50000.00000  50000.00000  50000.000000   50000.000000    50000.000000   \n",
       "mean       0.47442      0.37412      4.798474       0.700361        4.658200   \n",
       "std        0.49935      0.48390      2.761002       9.243785        2.917810   \n",
       "min        0.00000      0.00000      0.000000       0.000000        0.000000   \n",
       "25%        0.00000      0.00000      2.944439       0.000000        1.945910   \n",
       "50%        0.00000      0.00000      5.525453       0.000000        5.590987   \n",
       "75%        1.00000      1.00000      6.838405       0.000000        7.045994   \n",
       "max        1.00000      1.00000     10.817839     203.001000        9.993604   \n",
       "\n",
       "       当月视频播放类应用使用次数       ...         当月旅游资讯类应用使用次数           信用分   不同充值途径  \\\n",
       "count   50000.000000       ...          50000.000000  50000.000000  50000.0   \n",
       "mean        5.159212       ...             17.133007    618.053060      0.0   \n",
       "std         3.260769       ...             93.983089     42.443022      0.0   \n",
       "min         0.000000       ...              0.000000    422.000000      0.0   \n",
       "25%         2.397895       ...              0.000000    594.000000      0.0   \n",
       "50%         5.817111       ...              0.000000    627.000000      0.0   \n",
       "75%         7.793277       ...              4.000000    649.000000      0.0   \n",
       "max        11.611085       ...           1814.027000    719.000000      0.0   \n",
       "\n",
       "            当前费用稳定性      充值_余额_比例      月费_余额_比例      月费_缴费_比例      均费_缴费_比例  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.808802      0.555747      0.851325      1.843264      1.858965   \n",
       "std        0.059803      0.386572      0.176877      1.513286      1.526498   \n",
       "min        0.182525      0.000000      0.127589      0.168736      0.348693   \n",
       "25%        0.786325      0.000000      0.746553      0.837569      0.841298   \n",
       "50%        0.818677      0.713113      0.836579      0.951618      0.947006   \n",
       "75%        0.839307      0.834068      0.936021      3.091042      3.250762   \n",
       "max        1.171898      1.828958      1.869707      6.353069      6.104704   \n",
       "\n",
       "           均费_月费_比例        用户上网年龄  缴费金额是否能覆盖当月账单  最近一次缴费是否超过平均消费额  \\\n",
       "count  50000.000000  50000.000000   50000.000000     50000.000000   \n",
       "mean       0.816685    -58.406020      -1.517019        -1.532918   \n",
       "std        0.055808     56.534559       1.830333         1.837686   \n",
       "min        0.511288   -244.000000      -6.353069        -6.104704   \n",
       "25%        0.790764    -99.000000      -3.101892        -3.285038   \n",
       "50%        0.819245    -57.000000      -0.760483        -0.737390   \n",
       "75%        0.839817    -14.000000      -0.123937        -0.137328   \n",
       "max        2.439040     79.000000       4.573722         3.303590   \n",
       "\n",
       "       当月账单是否超过平均消费额      是否去过高档商场      是否_商场_电影      是否_商场_旅游     是否_商场_体育馆  \\\n",
       "count   50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       -0.015899      0.056960      0.029640      0.050940      0.044400   \n",
       "std         0.269912      0.231768      0.169594      0.219877      0.205984   \n",
       "min        -4.067160      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        -0.092383      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        -0.001344      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.083247      0.000000      0.000000      0.000000      0.000000   \n",
       "max         1.763218      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         是否_电影_体育馆      是否_电影_旅游     是否_旅游_体育馆  是否_商场_旅游_体育馆  是否_商场_电影_体育馆  \\\n",
       "count  50000.00000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.14640      0.167300      0.259060      0.041980      0.024780   \n",
       "std        0.35351      0.373247      0.438123      0.200545      0.155456   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.00000      0.000000      1.000000      0.000000      0.000000   \n",
       "max        1.00000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        是否_商场_电影_旅游  是否_体育馆_电影_旅游  是否_商场_体育馆_电影_旅游  \n",
       "count  50000.000000  50000.000000     50000.000000  \n",
       "mean       0.027820      0.110840         0.023940  \n",
       "std        0.164458      0.313937         0.152864  \n",
       "min        0.000000      0.000000         0.000000  \n",
       "25%        0.000000      0.000000         0.000000  \n",
       "50%        0.000000      0.000000         0.000000  \n",
       "75%        0.000000      0.000000         0.000000  \n",
       "max        1.000000      1.000000         1.000000  \n",
       "\n",
       "[8 rows x 52 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3 Single Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless features\n",
    "# print train_df.columns, len(train_df.columns)\n",
    "drop_cols = ['用户编码', '是否黑名单客户']\n",
    "\n",
    "X = train_df.drop(drop_cols + ['信用分'], axis=1)\n",
    "X_submit = test_df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dimension Reduction 降维\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=600)\n",
    "# pca.fit(X)\n",
    "# X = pca.fit_transform(X)\n",
    "# pca.fit(X_submit)\n",
    "# X_submit = pca.fit_transform(X_submit)\n",
    "# print X.shape, X_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-cv\n",
    "N_FOLDS = 5\n",
    "y = train_df['信用分']\n",
    "kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=2019)\n",
    "kf = kfold.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold: ', 0, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2609]\tvalid_0's l1: 14.8198\n",
      "('fold: ', 1, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2460]\tvalid_0's l1: 14.6959\n",
      "('fold: ', 2, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2451]\tvalid_0's l1: 14.8228\n",
      "('fold: ', 3, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2961]\tvalid_0's l1: 14.4808\n",
      "('fold: ', 4, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2838]\tvalid_0's l1: 14.8251\n",
      "('cv score for valid is: ', 0.06357735099782959)\n"
     ]
    }
   ],
   "source": [
    "# LightGBM: GBDT\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 5,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 2.5,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# 0--------------------------------------1\n",
    "\n",
    "\n",
    "\n",
    "# process the k-cv\n",
    "cv_pred = np.zeros(test_df.shape[0])\n",
    "valid_best_l2_all = 0\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "count = 0\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    print('fold: ',i, ' training')\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_idx, :], X.iloc[test_idx, :], y.iloc[train_idx], y.iloc[test_idx]\n",
    "#     X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n",
    "    data_train = lgb.Dataset(X_train, y_train)\n",
    "    data_test = lgb.Dataset(X_test, y_test)\n",
    "    lgb_model = lgb.train(params, data_train, num_boost_round=10000, valid_sets=data_test, \n",
    "                          verbose_eval=-1, early_stopping_rounds=50)\n",
    "    cv_pred += lgb_model.predict(X_submit, num_iteration=lgb_model.best_iteration)\n",
    "    valid_best_l2_all += lgb_model.best_score['valid_0']['l1']\n",
    "    \n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "#     fold_importance_df[\"feature\"] = list(unicode(X_train.columns))\n",
    "#     fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain', iteration=lgb_model.best_iteration)\n",
    "#     fold_importance_df[\"fold\"] = count + 1\n",
    "#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "cv_pred /= N_FOLDS\n",
    "valid_best_l2_all /= N_FOLDS\n",
    "print('cv score for valid is: ', 1 / (1 + valid_best_l2_all))\n",
    "\n",
    "# show the importance of features\n",
    "# display_importances(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06371758445225165"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.06364782116275812\n",
    "# 0.063714735700162436 ———— 去掉'年龄_网龄_比例'特征后\n",
    "# 0.063735568491715147 ———— 众数填充为零的年龄（平均数填充结果：0.063640145348041702，较差）\n",
    "# 0.063666002670369704 ———— 构造加减特征\n",
    "# 0.063684663314497278 ———— 构造'是否去过高档商场'\n",
    "# 0.063714215150177056 ———— 用众数替代‘用户话费敏感度’中的 0 值（平均数填充结果：0.063683775050515118，较差）\n",
    "# 0.0637013629544181 ———— 加上了base_process里面对左偏分布的处理\n",
    "\n",
    "0.06368864913531594\n",
    "\n",
    "0.06371758445225165\n",
    "\n",
    "\n",
    "0.06357735099782959\n",
    "0.06357735099782959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XGBoost\n",
    "# import xgboost as xgb\n",
    "# xgb_params={'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "#           'objective': 'reg:linear', 'eval_metric': 'mae', 'silent': True, 'nthread': 8}\n",
    "# from sklearn.model_selection import KFold\n",
    "# cv_pred_allxgb=0\n",
    "# en_amount=3\n",
    "# oof_xgb1=np.zeros(len(train_data))\n",
    "# prediction_xgb1=np.zeros(len(test_data))\n",
    "# for seed in range(en_amount):\n",
    "#     NFOLDS=5\n",
    "#     train_label=train_data['信用分']\n",
    "#     kfold=KFold(n_splits=NFOLDS, shuffle=True, random_state=seed+2019)\n",
    "#     kf=kfold.split(train_data,train_label)\n",
    "    \n",
    "#     train_data_use = train_data.drop(['用户编码','信用分'], axis=1)\n",
    "#     test_data_use = test_data.drop(['用户编码'], axis=1)\n",
    "    \n",
    "#     cv_pred = np.zeros(test_data.shape[0])\n",
    "#     valid_best_l2_all = 0\n",
    "    \n",
    "#     feature_importance_df = pd.DataFrame()\n",
    "#     count = 0\n",
    "    \n",
    "#     for i, (train_fold, validate) in enumerate(kf):\n",
    "#         print('fold: ',i, ' training')\n",
    "#         X_train, X_validate, label_train, label_validate = train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], train_label[train_fold], train_label[validate]\n",
    "#         dtrain = xgb.DMatrix(X_train, label_train)\n",
    "#         dvalid = xgb.DMatrix(X_validate, label_validate)\n",
    "#         watchlist = [(dtrain, 'train'), (dvalid, 'valid_data')]\n",
    "#         bst = xgb.train(dtrain=dtrain, num_boost_round=10000, evals=watchlist, early_stopping_rounds=100, verbose_eval=300, params=xgb_params)\n",
    "#         cv_pred += bst.predict(xgb.DMatrix(test_data_use), ntree_limit=bst.best_ntree_limit)\n",
    "#         oof_xgb1[validate]=bst.predict(xgb.DMatrix(X_validate),ntree_limit=bst.best_ntree_limit)\n",
    "#         prediction_xgb1+=bst.predict(xgb.DMatrix(test_data_use),ntree_limit=bst.best_ntree_limit)/kfold.n_splits\n",
    "#         count += 1\n",
    "        \n",
    "#     cv_pred /= NFOLDS\n",
    "#     cv_pred_allxgb+=cv_pred\n",
    "# cv_pred_allxgb /= en_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistical Regression 逻辑斯特回归\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# # process the k-cv\n",
    "# cv_pred = np.zeros(test_df.shape[0])\n",
    "# valid_best_l2_all = 0\n",
    "\n",
    "# feature_importance_df = pd.DataFrame()\n",
    "# count = 0\n",
    "# for i, (train_idx, test_idx) in enumerate(kf):\n",
    "#     print('fold: ',i, ' training')\n",
    "#     X_train, X_test, y_train, y_test = X.iloc[train_idx, :], X.iloc[test_idx, :], y.iloc[train_idx], y.iloc[test_idx]\n",
    "# #     X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n",
    "#     clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "#     valid_best_l2_all += mean_absolute_error(clf.predict(X_test), y_test)\n",
    "#     cv_pred += clf.predict(X_submit)\n",
    "\n",
    "# cv_pred /= N_FOLDS\n",
    "# print('cv score for valid is: ', 1/(1+valid_best_l2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold: ', 0, ' training')\n",
      "('fold: ', 1, ' training')\n",
      "('fold: ', 2, ' training')\n",
      "('fold: ', 3, ' training')\n",
      "('fold: ', 4, ' training')\n",
      "('cv score for valid is: ', 0.010147702585283056)\n"
     ]
    }
   ],
   "source": [
    "# # Linear Regression 线性回归\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# # process the k-cv\n",
    "# cv_pred = np.zeros(test_df.shape[0])\n",
    "# valid_best_l2_all = 0\n",
    "\n",
    "# feature_importance_df = pd.DataFrame()\n",
    "# count = 0\n",
    "# for i, (train_idx, test_idx) in enumerate(kf):\n",
    "#     print('fold: ',i, ' training')\n",
    "#     X_train, X_test, y_train, y_test = X.iloc[train_idx, :], X.iloc[test_idx, :], y.iloc[train_idx], y.iloc[test_idx]\n",
    "# #     X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n",
    "#     clf = LinearRegression().fit(X_train, y_train)\n",
    "#     valid_best_l2_all += mean_absolute_error(clf.predict(X_test), y_test)\n",
    "#     cv_pred += clf.predict(X_submit)\n",
    "\n",
    "# cv_pred /= N_FOLDS\n",
    "# print('cv score for valid is: ', 1/(1+valid_best_l2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold: ', 0, ' training')\n",
      "('fold: ', 1, ' training')\n",
      "('fold: ', 2, ' training')\n",
      "('fold: ', 3, ' training')\n",
      "('fold: ', 4, ' training')\n",
      "('cv score for valid is: ', 0.010166458073200388)\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# process the k-cv\n",
    "cv_pred = np.zeros(test_df.shape[0])\n",
    "valid_best_l2_all = 0\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "count = 0\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    print('fold: ',i, ' training')\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_idx, :], X.iloc[test_idx, :], y.iloc[train_idx], y.iloc[test_idx]\n",
    "#     X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n",
    "    clf = Ridge(alpha=.5).fit(X_train, y_train)\n",
    "    valid_best_l2_all += mean_absolute_error(clf.predict(X_test), y_test)\n",
    "    cv_pred += clf.predict(X_submit)\n",
    "\n",
    "cv_pred /= N_FOLDS\n",
    "model_score = 1/(1+valid_best_l2_all)\n",
    "print('cv score for valid is: ', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold: ', 0, ' training')\n",
      "('fold: ', 1, ' training')\n",
      "('fold: ', 2, ' training')\n",
      "('fold: ', 3, ' training')\n",
      "('fold: ', 4, ' training')\n",
      "('cv score for valid is: ', 0.01013072051309375)\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# process the k-cv\n",
    "cv_pred = np.zeros(test_df.shape[0])\n",
    "valid_best_l2_all = 0\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "count = 0\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    print('fold: ',i, ' training')\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_idx, :], X.iloc[test_idx, :], y.iloc[train_idx], y.iloc[test_idx]\n",
    "#     X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n",
    "    clf = Lasso(alpha=.1).fit(X_train, y_train)\n",
    "    valid_best_l2_all += mean_absolute_error(clf.predict(X_test), y_test)\n",
    "    cv_pred += clf.predict(X_submit)\n",
    "\n",
    "cv_pred /= N_FOLDS\n",
    "print('cv score for valid is: ', 1/(1+valid_best_l2_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4 Single model submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ./submission/baseline_20190322-21:11:36_0.0101664580732_.csv <|-.-|>\n"
     ]
    }
   ],
   "source": [
    "submit_df = test_df[['用户编码']]\n",
    "submit_df['score'] = cv_pred\n",
    "submit_df.columns = ['id', 'score']\n",
    "submit_df['score'] = submit_df['score'].apply(lambda x: int(np.round(x)))\n",
    "\n",
    "csv_name = './submission/baseline_' + str(time.strftime('%Y%m%d-%H:%M:%S')) + '_{}_'.format(model_score) + '.csv'\n",
    "print 'saving ' + csv_name + ' <|-.-|>'\n",
    "submit_df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4651f98c82948b186bdcdc8108381b4</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aeb10247db4e4d67b2550bbc42ff9827</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5af23a1e0e77410abb25e9a7eee510aa</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43c64379d3c24a15b8478851b22049e4</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1687f3b8a6f4910bd0b13eb634056e2</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52795d470db4478584f6c92f66af0294</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0d758e1b10cc4f618dda9f87fc948068</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b05585f9635245f282bf2cffd3c5773c</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acde81ca14eb429a983bec773e16098c</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1f78ee310e9d48449b8d5a1fd1537286</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  score\n",
       "0  a4651f98c82948b186bdcdc8108381b4    534\n",
       "1  aeb10247db4e4d67b2550bbc42ff9827    441\n",
       "2  5af23a1e0e77410abb25e9a7eee510aa    524\n",
       "3  43c64379d3c24a15b8478851b22049e4    525\n",
       "4  f1687f3b8a6f4910bd0b13eb634056e2    513\n",
       "5  52795d470db4478584f6c92f66af0294    516\n",
       "6  0d758e1b10cc4f618dda9f87fc948068    523\n",
       "7  b05585f9635245f282bf2cffd3c5773c    489\n",
       "8  acde81ca14eb429a983bec773e16098c    453\n",
       "9  1f78ee310e9d48449b8d5a1fd1537286    446"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### —————————————————————————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5 Model ensembling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless features\n",
    "drop_cols = ['用户编码', '是否黑名单客户']\n",
    "\n",
    "X = train_df.drop(drop_cols + ['信用分'], axis=1)\n",
    "X_submit = test_df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold: ', 0, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2324]\tvalid_0's l1: 14.7854\n",
      "('fold: ', 1, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2317]\tvalid_0's l1: 14.6964\n",
      "('fold: ', 2, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3255]\tvalid_0's l1: 14.7701\n",
      "('fold: ', 3, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3321]\tvalid_0's l1: 14.477\n",
      "('fold: ', 4, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2141]\tvalid_0's l1: 14.8283\n",
      "('cv score for valid is: ', 0.06364782116275812)\n",
      "('fold: ', 0, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2324]\tvalid_0's l1: 14.7854\n",
      "('fold: ', 1, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2317]\tvalid_0's l1: 14.6964\n",
      "('fold: ', 2, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3255]\tvalid_0's l1: 14.7701\n",
      "('fold: ', 3, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3321]\tvalid_0's l1: 14.477\n",
      "('fold: ', 4, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2141]\tvalid_0's l1: 14.8283\n",
      "('cv score for valid is: ', 0.063647821162758106)\n",
      "('fold: ', 0, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2324]\tvalid_0's l1: 14.7854\n",
      "('fold: ', 1, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2317]\tvalid_0's l1: 14.6964\n",
      "('fold: ', 2, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3255]\tvalid_0's l1: 14.7701\n",
      "('fold: ', 3, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3321]\tvalid_0's l1: 14.477\n",
      "('fold: ', 4, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2141]\tvalid_0's l1: 14.8283\n",
      "('cv score for valid is: ', 0.063647821162758106)\n"
     ]
    }
   ],
   "source": [
    "# LightGBM params\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 5,\n",
    "    'lambda_l2': 5, 'lambda_l1': 0\n",
    "}\n",
    "\n",
    "# process the k-cv\n",
    "cv_pred_all = 0\n",
    "en_amount = 3\n",
    "for seed in range(en_amount):\n",
    "    # k-cv\n",
    "    N_FOLDS = 5\n",
    "    y = train_df['信用分']\n",
    "    kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=2019)\n",
    "    kf = kfold.split(X, y)\n",
    "\n",
    "    # process the k-cv\n",
    "    cv_pred = np.zeros(test_df.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_idx, test_idx) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train_idx, :], X.iloc[test_idx, :], y.iloc[train_idx], y.iloc[test_idx]\n",
    "#         X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n",
    "        data_train = lgb.Dataset(X_train, y_train)\n",
    "        data_test = lgb.Dataset(X_test, y_test)\n",
    "        lgb_model = lgb.train(params, data_train, num_boost_round=10000, valid_sets=data_test, \n",
    "                              verbose_eval=-1, early_stopping_rounds=50)\n",
    "        cv_pred += lgb_model.predict(X_submit, num_iteration=lgb_model.best_iteration)\n",
    "        valid_best_l2_all += lgb_model.best_score['valid_0']['l1']\n",
    "\n",
    "#         fold_importance_df = pd.DataFrame()\n",
    "#         fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "#         fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain', iteration=lgb_model.best_iteration)\n",
    "#         fold_importance_df[\"fold\"] = count + 1\n",
    "#         feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        count += 1\n",
    "\n",
    "    cv_pred /= N_FOLDS\n",
    "    valid_best_l2_all /= N_FOLDS\n",
    "    print('cv score for valid is: ', 1/(1+valid_best_l2_all))\n",
    "    \n",
    "    cv_pred_all += cv_pred\n",
    "\n",
    "# avg cv_pred_all\n",
    "cv_pred_all = cv_pred_all / en_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fold: ', 0, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2019]\tvalid_0's l1: 14.8025\n",
      "('fold: ', 1, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2143]\tvalid_0's l1: 14.6985\n",
      "('fold: ', 2, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2732]\tvalid_0's l1: 14.8106\n",
      "('fold: ', 3, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2004]\tvalid_0's l1: 14.5162\n",
      "('fold: ', 4, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2499]\tvalid_0's l1: 14.7874\n",
      "('cv score for valid is: ', 0.063600933726241329)\n",
      "('fold: ', 0, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2019]\tvalid_0's l1: 14.8025\n",
      "('fold: ', 1, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2143]\tvalid_0's l1: 14.6985\n",
      "('fold: ', 2, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2732]\tvalid_0's l1: 14.8106\n",
      "('fold: ', 3, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2004]\tvalid_0's l1: 14.5162\n",
      "('fold: ', 4, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2499]\tvalid_0's l1: 14.7874\n",
      "('cv score for valid is: ', 0.063600933726241329)\n",
      "('fold: ', 0, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2019]\tvalid_0's l1: 14.8025\n",
      "('fold: ', 1, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2143]\tvalid_0's l1: 14.6985\n",
      "('fold: ', 2, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2732]\tvalid_0's l1: 14.8106\n",
      "('fold: ', 3, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2004]\tvalid_0's l1: 14.5162\n",
      "('fold: ', 4, ' training')\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2499]\tvalid_0's l1: 14.7874\n",
      "('cv score for valid is: ', 0.063600933726241343)\n"
     ]
    }
   ],
   "source": [
    "#para\n",
    "params2 = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'mae',\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'max_depth': 5,\n",
    "    'lambda_l2': 5, 'lambda_l1': 0,'nthread': 8,\n",
    "    'seed': 89\n",
    "}\n",
    "\n",
    "# process the k-cv\n",
    "cv_pred_all2 = 0\n",
    "en_amount = 3\n",
    "for seed in range(en_amount):\n",
    "    # k-cv\n",
    "    N_FOLDS = 5\n",
    "    y = train_df['信用分']\n",
    "    kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=2019)\n",
    "    kf = kfold.split(X, y)\n",
    "\n",
    "    # process the k-cv\n",
    "    cv_pred = np.zeros(test_df.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_idx, test_idx) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train_idx, :], X.iloc[test_idx, :], y.iloc[train_idx], y.iloc[test_idx]\n",
    "#         X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n",
    "        data_train = lgb.Dataset(X_train, y_train)\n",
    "        data_test = lgb.Dataset(X_test, y_test)\n",
    "        lgb_model = lgb.train(params2, data_train, num_boost_round=10000, valid_sets=data_test, \n",
    "                              verbose_eval=-1, early_stopping_rounds=50)\n",
    "        cv_pred += lgb_model.predict(X_submit, num_iteration=lgb_model.best_iteration)\n",
    "        valid_best_l2_all += lgb_model.best_score['valid_0']['l1']\n",
    "\n",
    "#         fold_importance_df = pd.DataFrame()\n",
    "#         fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "#         fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain', iteration=lgb_model.best_iteration)\n",
    "#         fold_importance_df[\"fold\"] = count + 1\n",
    "#         feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        count += 1\n",
    "\n",
    "    cv_pred /= N_FOLDS\n",
    "    valid_best_l2_all /= N_FOLDS\n",
    "    print('cv score for valid is: ', 1/(1+valid_best_l2_all))\n",
    "    \n",
    "    cv_pred_all2 += cv_pred\n",
    "\n",
    "# avg cv_pred_all\n",
    "cv_pred_all2 = cv_pred_all2 / en_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #6 Model Ensembling Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = test_df[['用户编码']]\n",
    "submit_df['score'] = (cv_pred_all + cv_pred_all2) / 2\n",
    "submit_df.columns = ['id', 'score']\n",
    "submit_df['score1'] = cv_pred_all\n",
    "submit_df['score2'] = cv_pred_all2\n",
    "\n",
    "# int\n",
    "submit_df['score'] = submit_df['score'].apply(lambda x: int(np.round(x)))\n",
    "submit_df[['id','score']].to_csv('./submission/model_ensemble_baseline_2019-03-07T09:40:35_0.063600933726241343.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
